#calculating the proportion of BIPOC faculty with the counts above
mimp_df$iBIPOC_pr = mimp_df$count.BIPOC/mimp_df$count.nMiss
#we can assign more than one value to the same factor by repeating the label
mimp_df$format = factor(mimp_df$format,
levels = c(1,2,3,4,5),
labels = c("InPerson", "Blend", "Blend", "Online", is.na(5)))
mimp_df <-  select (mimp_df, ID, iBIPOC_pr, cmBlack, Belong_1:Belong_3, Blst_1:Blst_6, cEval_1, cEval_13, cEval_19, format)
p_missing <- unlist(lapply(mimp_df, function(x) sum(is.na(x))))/nrow(mimp_df)
sort(p_missing[p_missing > 0], decreasing = TRUE)
#Calculating number and proportion of item-level missingness
mimp_df$nmiss <- mimp_df%>%
select(iBIPOC_pr:format) %>% #the colon allows us to include all variables between the two listed (the variables need to be in order)
is.na %>%
rowSums
mimp_df<- mimp_df%>%
mutate(prop_miss = (nmiss/15)*100) #11 is the number of variables included in calculating the proportion
mimp_df <- filter(mimp_df, prop_miss <= 50)  #update df to have only those with at least 90% of complete data
mimp_df <-  select (mimp_df, ID, iBIPOC_pr, cmBlack, Belong_1:Belong_3, Blst_1:Blst_6, cEval_1, cEval_13, cEval_19, format)
set.seed(210324) #you can pick any number you want, today I'm using today's datestamp
library(mice)
# runs the mice code with 0 iterations
imp <- mice(mimp_df, maxit = 0)
# Extract predictorMatrix and methods of imputation
predM = imp$predictorMatrix
meth = imp$method
#These variables are left in the dataset, but setting them = 0 means they are not used as predictors.
#We want our ID to be retained in the df.  There's nothing missing from it, and we don't want it used as a predictor, so it will just hang out.
predM[, c("ID")]=0
#If you like, view the first few rows of the predictor matrix
#head(predM)
#We don't have any ordered categorical variables, but if we did we would follow this format
#poly <- c("Var1", "Var2")
#We don't have any dichotomous variables, but if we did we would follow this format
#log <- c("Var3", "Var4")
#Uunordered categorical variables (nominal variables), but if we did we would follow this format
poly2 <- c("format")
#Turn their methods matrix into the specified imputation models
#Remove the hashtag if you have any of these variables
#meth[poly] = "polr"
#meth[log] = "logreg"
meth[poly2] = "polyreg"
meth
# With this command, we tell mice to impute the anesimpor2 data, create 5vvdatasets, use predM as the predictor matrix and don't print the imputation process.
#If you would like to see the process (or if the process is failing to execute) set print as TRUE; seeing where the execution halts can point to problematic variables (more notes at end of lecture)
imp2 <- mice(mimp_df, maxit = 5,
predictorMatrix = predM,
method = meth, print =  FALSE)
# First, turn the datasets into long format
# This procedure is, best I can tell, unique to mice and wouldn't work for repeated measures designs
mimp_long <- mice::complete(imp2, action="long", include = TRUE)
# With this command, we tell mice to impute the anesimpor2 data, create 5vvdatasets, use predM as the predictor matrix and don't print the imputation process.
#If you would like to see the process (or if the process is failing to execute) set print as TRUE; seeing where the execution halts can point to problematic variables (more notes at end of lecture)
imp2 <- mice(mimp_df, maxit = 5,
predictorMatrix = predM,
method = meth, print =  FALSE)
p_missing_mimp_long <- unlist(lapply(mimp_long, function(x) sum(is.na(x))))/nrow(mimp_long)
sort(p_missing_mimp_long[p_missing_mimp_long > 0], decreasing = TRUE)#check to see if this works
mimp_long<- mimp_long %>%
mutate(rBlst_1 = 8 - Blst_1) #if you had multiple items, you could add a pipe (%>%) at the end of the line and add more until the last one
library(sjstats)
#Making the list of variables
Belonging_vars <- c('Belong_1','Belong_2','Belong_3')
ResponseBL_vars <- c('rBlst_1', 'Blst_4','Blst_6')
StigmaBL_vars <- c('Blst_2', 'Blst_3','Blst_5')
ClimateBL_vars <- c('rBlst_1', 'Blst_4','Blst_6','Blst_2', 'Blst_3','Blst_5' )
#Creating the new variables
mimp_long$Belonging <- mean_n(mimp_long[,Belonging_vars], .65)
mimp_long$ResponseBL <- mean_n(mimp_long[,ResponseBL_vars], .80)
mimp_long$StigmaBL <- mean_n(mimp_long[,StigmaBL_vars], .80)
mimp_long$ClimateBL <- mean_n(mimp_long[,ClimateBL_vars], .80)
library(sjstats)
#Making the list of variables
Belonging_vars <- c('Belong_1','Belong_2','Belong_3')
ResponseBL_vars <- c('rBlst_1', 'Blst_4','Blst_6')
StigmaBL_vars <- c('Blst_2', 'Blst_3','Blst_5')
ClimateBL_vars <- c('rBlst_1', 'Blst_4','Blst_6','Blst_2', 'Blst_3','Blst_5' )
#Creating the new variables
mimp_long$Belonging <- mean_n(mimp_long[,Belonging_vars], .65)
mimp_long$ResponseBL <- mean_n(mimp_long[,ResponseBL_vars], .80)
mimp_long$StigmaBL <- mean_n(mimp_long[,StigmaBL_vars], .80)
mimp_long$ClimateBL <- mean_n(mimp_long[,ClimateBL_vars], .80)
# Convert to mids type - mice can work with this type
mimp_mids<-as.mids(mimp_long)
fitimp <- with(mimp_mids,
lm(ClimateBL ~ Belonging + cmBlack + iBIPOC_pr))
# to get the 5, individual imputations
summary(fitimp)
# the pooled result
pooledests <- pool(fitimp)
pooledests
#str(pooledests)
sumpooled <- summary(pool(fitimp))
sumpooled
#str(sumpooled)
library(formattable)
mimpBel_B <- digits(sumpooled$estimate[2],3)
mimpBel_B
mimpBel_p <- digits(sumpooled$p.value[2],3)
mimpBel_p
mimp_cmBl_B <- digits(sumpooled$estimate[3],3)
mimp_cmBl_B
mimp_cmBl_p <- digits(sumpooled$p.value[3],3)
mimp_cmBl_p
mimp_i_B <- digits(sumpooled$estimate[4],3)
mimp_i_B
mimp_i_p <- digits(sumpooled$p.value[4],3)
mimp_i_p
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get different token if you are changing between accounts
library(qualtRics)
#View this as an object (found in the right: Environment).
#Get survey id # for the next command
#If this is showing you the WRONG list of surveys, you are pulling from the wrong Qualtrics account (i.e., maybe this one instead of your own). Go back and change your API token (it saves your old one). Changing the API likely requires a restart of R.
surveys
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get different token if you are changing between accounts
library(qualtRics)
surveys <- all_surveys()
#View this as an object (found in the right: Environment).
#Get survey id # for the next command
#If this is showing you the WRONG list of surveys, you are pulling from the wrong Qualtrics account (i.e., maybe this one instead of your own). Go back and change your API token (it saves your old one). Changing the API likely requires a restart of R.
surveys
#obtained with the survey ID #
#"surveyID" should be the ID from above
#"verbose" prints messages to the R console
#"label", when TRUE, imports data as text responses; if FALSE prints the data as numerical responses
#"convert", when TRUE, attempts to convert certain question types to the "proper" data type in R; because I don't like guessing, I want to set up my own factors.
#"force_request", when TRUE, always downloads the survey from the API instead of from a temporary directory (i.e., it always goes to the primary source)
# "import_id", when TRUE includes the unique Qualtrics-assigned ID; since I have provided labels, I want false
QTRX_df <- fetch_survey(surveyID = "SV_b2cClqAlLGQ6nLU",useLocalTime = TRUE,
verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
View(QTRX_df)
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get different token if you are changing between accounts
library(qualtRics)
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get different token if you are changing between accounts
library(qualtRics)
#qualtrics_api_credentials(api_key = "mUgPMySYkiWpMFkwHale1QE5HNmh5LRUaA8d9PDg",
#base_url = "spupsych.az1.qualtrics.com", overwrite = TRUE, install = TRUE)
surveys <- all_surveys()
#View this as an object (found in the right: Environment).
#Get survey id # for the next command
#If this is showing you the WRONG list of surveys, you are pulling from the wrong Qualtrics account (i.e., maybe this one instead of your own). Go back and change your API token (it saves your old one). Changing the API likely requires a restart of R.
surveys
#obtained with the survey ID #
#"surveyID" should be the ID from above
#"verbose" prints messages to the R console
#"label", when TRUE, imports data as text responses; if FALSE prints the data as numerical responses
#"convert", when TRUE, attempts to convert certain question types to the "proper" data type in R; because I don't like guessing, I want to set up my own factors.
#"force_request", when TRUE, always downloads the survey from the API instead of from a temporary directory (i.e., it always goes to the primary source)
# "import_id", when TRUE includes the unique Qualtrics-assigned ID; since I have provided labels, I want false
QTRX_df <- fetch_survey(surveyID = "SV_b2cClqAlLGQ6nLU",useLocalTime = TRUE,
verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get different token if you are changing between accounts
library(qualtRics)
#qualtrics_api_credentials(api_key = "mUgPMySYkiWpMFkwHale1QE5HNmh5LRUaA8d9PDg",
#base_url = "spupsych.az1.qualtrics.com", overwrite = TRUE, install = TRUE)
surveys <- all_surveys()
#View this as an object (found in the right: Environment).
#Get survey id # for the next command
#If this is showing you the WRONG list of surveys, you are pulling from the wrong Qualtrics account (i.e., maybe this one instead of your own). Go back and change your API token (it saves your old one). Changing the API likely requires a restart of R.
surveys
#obtained with the survey ID
#"surveyID" should be the ID from above
#"verbose" prints messages to the R console
#"label", when TRUE, imports data as text responses; if FALSE prints the data as numerical responses
#"convert", when TRUE, attempts to convert certain question types to the "proper" data type in R; because I don't like guessing, I want to set up my own factors.
#"force_request", when TRUE, always downloads the survey from the API instead of from a temporary directory (i.e., it always goes to the primary source)
# "import_id", when TRUE includes the unique Qualtrics-assigned ID; since I have provided labels, I want false
QTRX_df <- fetch_survey(surveyID = "SV_b2cClqAlLGQ6nLU",useLocalTime = TRUE,
verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
# the filter command is used when we are making inclusion/exclusion decisions about rows
# != means do not include cases with "preview"
library(tidyverse)
QTRX_df <- filter (QTRX_df, DistributionChannel != "preview")
#FYI, another way that doesn't use tidyverse, but gets the same result
#QTRX_df <- QTRX_df[!QTRX_df$DistributionChannel == "preview",]
# I created an object that lists how many rows/cases remain.
# I used inline text below to update the text with the new number
attempts <- nrow(QTRX_df)
attempts
# == are used
QTRX_df <-(filter (QTRX_df, Consent == 1))
consented_attempts <- nrow(QTRX_df)
consented_attempts
#obtained with the survey ID
#"surveyID" should be the ID from above
#"verbose" prints messages to the R console
#"label", when TRUE, imports data as text responses; if FALSE prints the data as numerical responses
#"convert", when TRUE, attempts to convert certain question types to the "proper" data type in R; because I don't like guessing, I want to set up my own factors.
#"force_request", when TRUE, always downloads the survey from the API instead of from a temporary directory (i.e., it always goes to the primary source)
# "import_id", when TRUE includes the unique Qualtrics-assigned ID; since I have provided labels, I want false
QTRX_df <- fetch_survey(surveyID = "SV_b2cClqAlLGQ6nLU", time_zone = TRUE,
verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get different token if you are changing between accounts
library(qualtRics)
#qualtrics_api_credentials(api_key = "mUgPMySYkiWpMFkwHale1QE5HNmh5LRUaA8d9PDg",
#base_url = "spupsych.az1.qualtrics.com", overwrite = TRUE, install = TRUE)
surveys <- all_surveys()
#View this as an object (found in the right: Environment).
#Get survey id # for the next command
#If this is showing you the WRONG list of surveys, you are pulling from the wrong Qualtrics account (i.e., maybe this one instead of your own). Go back and change your API token (it saves your old one). Changing the API likely requires a restart of R.
surveys
#obtained with the survey ID
#"surveyID" should be the ID from above
#"verbose" prints messages to the R console
#"label", when TRUE, imports data as text responses; if FALSE prints the data as numerical responses
#"convert", when TRUE, attempts to convert certain question types to the "proper" data type in R; because I don't like guessing, I want to set up my own factors.
#"force_request", when TRUE, always downloads the survey from the API instead of from a temporary directory (i.e., it always goes to the primary source)
# "import_id", when TRUE includes the unique Qualtrics-assigned ID; since I have provided labels, I want false
QTRX_df <- fetch_survey(surveyID = "SV_b2cClqAlLGQ6nLU",
verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
#useLocalTime = TRUE,
#obtained with the survey ID
#"surveyID" should be the ID from above
#"verbose" prints messages to the R console
#"label", when TRUE, imports data as text responses; if FALSE prints the data as numerical responses
#"convert", when TRUE, attempts to convert certain question types to the "proper" data type in R; because I don't like guessing, I want to set up my own factors.
#"force_request", when TRUE, always downloads the survey from the API instead of from a temporary directory (i.e., it always goes to the primary source)
# "import_id", when TRUE includes the unique Qualtrics-assigned ID; since I have provided labels, I want false
QTRX_df <- fetch_survey(surveyID = "SV_b2cClqAlLGQ6nLU", useLocalTime = TRUE,
verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get different token if you are changing between accounts
install.packages("qualtRics")
install.packages("qualtRics")
#obtained with the survey ID
#"surveyID" should be the ID from above
#"verbose" prints messages to the R console
#"label", when TRUE, imports data as text responses; if FALSE prints the data as numerical responses
#"convert", when TRUE, attempts to convert certain question types to the "proper" data type in R; because I don't like guessing, I want to set up my own factors.
#"force_request", when TRUE, always downloads the survey from the API instead of from a temporary directory (i.e., it always goes to the primary source)
# "import_id", when TRUE includes the unique Qualtrics-assigned ID; since I have provided labels, I want false
QTRX_df <- fetch_survey(surveyID = "SV_b2cClqAlLGQ6nLU", time_zone = NULL,
verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get different token if you are changing between accounts
library(qualtRics)
#qualtrics_api_credentials(api_key = "mUgPMySYkiWpMFkwHale1QE5HNmh5LRUaA8d9PDg",
#base_url = "spupsych.az1.qualtrics.com", overwrite = TRUE, install = TRUE)
surveys <- all_surveys()
#View this as an object (found in the right: Environment).
#Get survey id # for the next command
#If this is showing you the WRONG list of surveys, you are pulling from the wrong Qualtrics account (i.e., maybe this one instead of your own). Go back and change your API token (it saves your old one). Changing the API likely requires a restart of R.
surveys
#obtained with the survey ID
#"surveyID" should be the ID from above
#"verbose" prints messages to the R console
#"label", when TRUE, imports data as text responses; if FALSE prints the data as numerical responses
#"convert", when TRUE, attempts to convert certain question types to the "proper" data type in R; because I don't like guessing, I want to set up my own factors.
#"force_request", when TRUE, always downloads the survey from the API instead of from a temporary directory (i.e., it always goes to the primary source)
# "import_id", when TRUE includes the unique Qualtrics-assigned ID; since I have provided labels, I want false
QTRX_df <- fetch_survey(surveyID = "SV_b2cClqAlLGQ6nLU", time_zone = NULL,
verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
#useLocalTime = TRUE,
#obtained with the survey ID
#"surveyID" should be the ID from above
#"verbose" prints messages to the R console
#"label", when TRUE, imports data as text responses; if FALSE prints the data as numerical responses
#"convert", when TRUE, attempts to convert certain question types to the "proper" data type in R; because I don't like guessing, I want to set up my own factors.
#"force_request", when TRUE, always downloads the survey from the API instead of from a temporary directory (i.e., it always goes to the primary source)
# "import_id", when TRUE includes the unique Qualtrics-assigned ID; since I have provided labels, I want false
QTRX_df <- fetch_survey(surveyID = "SV_b2cClqAlLGQ6nLU", time_zone = NULL, verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
#useLocalTime = TRUE,
View(QTRX_df)
# the filter command is used when we are making inclusion/exclusion decisions about rows
# != means do not include cases with "preview"
library(tidyverse)
# the filter command is used when we are making inclusion/exclusion decisions about rows
# != means do not include cases with "preview"
library(tidyverse)
QTRX_df <- filter (QTRX_df, DistributionChannel != "preview")
#FYI, another way that doesn't use tidyverse, but gets the same result
#QTRX_df <- QTRX_df[!QTRX_df$DistributionChannel == "preview",]
# I created an object that lists how many rows/cases remain.
# I used inline text below to update the text with the new number
attempts <- nrow(QTRX_df)
attempts
# == are used
QTRX_df <-(filter (QTRX_df, Consent == 1))
consented_attempts <- nrow(QTRX_df)
consented_attempts
QTRX_df <-(filter (QTRX_df, USinst == 0))
US_inclusion <- nrow(QTRX_df)
US_inclusion
library(tidyverse)
library(tidyverse)
QTRX_df <- rename(QTRX_df, iRace1 = '1_iRace', iRace2 = '2_iRace', iRace3 = '3_iRace', iRace4 = '4_iRace', iRace5 = '5_iRace', iRace6 = '6_iRace', iRace7 = '7_iRace', iRace8 = '8_iRace', iRace9 = '9_iRace', iRace10 = '10_iRace')
QTRX_df <- rename(QTRX_df, cmBiMulti = Race_10, cmBlack = Race_1, cmNBPoC = Race_7, cmWhite = Race_8, cmUnsure = Race_2)
QTRX_df <- QTRX_df %>% mutate(ID = row_number())
#moving the ID number to the first column; requires
QTRX_df <- QTRX_df%>%select(ID, everything())
#You can use the ":" to include all variables from the first to last variable in any sequence; I could have written this more efficiently.  I just like to "see" my scales and clusters of variables.
Model_df <-(select (QTRX_df, ID, iRace1, iRace2, iRace3, iRace4, iRace5, iRace6, iRace7, iRace8, iRace9, iRace10, cmBiMulti, cmBlack, cmNBPoC, cmWhite, cmUnsure, Belong_1:Belong_3, Blst_1:Blst_6))
View(Model_df)
write.table(Model_df, file="BlackStntsModel210318.csv", sep=",", col.names=TRUE, row.names=FALSE)
library(qualtRics)
QTRX_csv <- read_survey("ReC_Download210319.csv", strip_html = TRUE, import_id = FALSE, time_zone=NULL, legacy = FALSE)
View(QTRX_csv)
?glimpse
scrub_df <- read.csv ("BlackStntsModel210318.csv", head = TRUE, sep = ",")
str(scrub_df)
View(scrub_df)
str(scrub_df$iRace1)
scrub_df$tRace1 = factor(scrub_df$iRace1,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace2 = factor(scrub_df$iRace2,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace3 = factor(scrub_df$iRace3,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace4 = factor(scrub_df$iRace4,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace5 = factor(scrub_df$iRace5,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace6 = factor(scrub_df$iRace6,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace7 = factor(scrub_df$iRace7,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace8 = factor(scrub_df$iRace8,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace9 = factor(scrub_df$iRace9,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace10 = factor(scrub_df$iRace10,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
library(tidyverse)
glimpse(scrub_df)
scrub_df$count.BIPOC <- apply(scrub_df[c("tRace1", "tRace2", "tRace3", "tRace4", "tRace5", "tRace6", "tRace7", "tRace8", "tRace9", "tRace10")], 1, function(x) sum(x %in% c("Black", "nBpoc", "BiMulti")))
scrub_df$count.nMiss <- apply(scrub_df[c("tRace1", "tRace2", "tRace3", "tRace4", "tRace5", "tRace6", "tRace7", "tRace8", "tRace9", "tRace10")], 1, function(x) sum(!is.na(x)))
scrub_df$iBIPOC_pr = scrub_df$count.BIPOC/scrub_df$count.nMiss
scrub_df <-(select (scrub_df, ID, iBIPOC_pr, cmBlack, Belong_1:Belong_3, Blst_1:Blst_6))
scrub_df$nmiss <- scrub_df%>%
select(iBIPOC_pr:Blst_6) %>% #the colon allows us to include all variables between the two listed (the variables need to be in order)
is.na %>%
rowSums
scrub_df<- scrub_df%>%
mutate(prop_miss = (nmiss/11)*100) #11 is the number of variables included in calculating the proportion
library(formattable)
CaseMiss<-psych::describe(scrub_df$prop_miss)
CaseMiss
missMin <- digits(CaseMiss$min, 0)
missMax <- digits(CaseMiss$max, 0)
library(formattable)
CaseMiss<-psych::describe(scrub_df$prop_miss)
CaseMiss
missMin <- digits(CaseMiss$min, 0)
missMax <- digits(CaseMiss$max, 0)
misssMax
library(formattable)
CaseMiss<-psych::describe(scrub_df$prop_miss)
CaseMiss
missMin <- digits(CaseMiss$min, 0)
missMax <- digits(CaseMiss$max, 0)
missMax
missMin
scrub_df <- filter(scrub_df, prop_miss <= 90)  #update df to have only those with at least 90% of complete data
scrub_df <- scrub_df %>%
select (-c(ID, nmiss, prop_miss))#further update to exclude the n_miss and prop_miss variables
#install.packages("formattable")
CellsMiss <- percent(mean(is.na(scrub_df)))#what proportion of cells missing across entire dataset
CaseComplete <- percent(mean(complete.cases(scrub_df)))#what proportion of cases (rows) are complete (nonmissing)
CellsMiss
CaseComplete
#Using the package: mice
library(mice)
#Using the package: mice
library(mice)
mice_out <- md.pattern(scrub_df, plot = TRUE, rotate.names = TRUE)
mice_out
write.csv (mice_out, file="mice_out.csv") #optional to write it to a .csv file
scrub_df<- scrub_df %>%
mutate(rBlst_1 = 8 - Blst_1) #if you had multiple items, you could add a pipe (%>%) at the end of the line and add more until the last one
scrub_df<- scrub_df %>%
mutate(rBlst_1 = 8 - Blst_1%>%) #if you had multiple items, you could add a pipe (%>%) at the end of the line and add more until the last one
scrub_df<- scrub_df %>%
mutate(rBlst_1 = 8 - Blst_1) #if you had multiple items, you could add a pipe (%>%) at the end of the line and add more until the last one
Belonging_vars <- c('Belong_1','Belong_2','Belong_3')
ResponseBL_vars <- c('rBlst_1', 'Blst_4','Blst_6')
StigmaBL_vars <- c('Blst_2', 'Blst_3','Blst_5')
ClimateBL_vars <- c('rBlst_1', 'Blst_4','Blst_6','Blst_2', 'Blst_3','Blst_5' )
scrub_df$Belonging <- mean_n(scrub_df[,Belonging_vars], .65)
library(sjstats)
scrub_df$Belonging <- mean_n(scrub_df[,Belonging_vars], .65)
scrub_df$ResponseBL <- mean_n(scrub_df[,ResponseBL_vars], .80)
scrub_df$StigmaBL <- mean_n(scrub_df[,StigmaBL_vars], .80)
scrub_df$ClimateBL <- mean_n(scrub_df[,ClimateBL_vars], .80)
library(tidyverse)
scrub_df <- scrub_df %>% mutate(ID = row_number())
#moving the ID number to the first column; requires
scrub_df <- scrub_df%>%select(ID, everything())
write.table(scrub_df, file="BlStItmsScrs210320.csv", sep=",", col.names=TRUE, row.names=FALSE)
scored <-(select (scrub_df, iBIPOC_pr, cmBlack, Belonging, ResponseBL, StigmaBL, ClimateBL))
View(scored)
ScoredCaseMiss <- nrow(scored) #I produced this object for the sole purpose of feeding the number of cases into the inline text, below
library(psych)
scored$n_miss <- scored%>%
select(iBIPOC_pr:ClimateBL) %>%
is.na %>%
rowSums
scored<- scored%>%
mutate(prop_miss = (n_miss/6)*100)%>%
arrange(desc(n_miss))
ScoredPrMiss <- psych::describe(scored$prop_miss)
ScoredPrMiss
ScrdMissMin <- digits(ScoredPrMiss$min, 0)#this object is displayed below and I use input from  it for the inline text used in the write-up
ScrdMissMax <- digits(ScoredPrMiss$max, 0)
ScrdMissMin
ScrdMissMax
scored <- filter(scored, prop_miss <= 20)  #update df to have only those with at least 20% of complete data (this is an arbitrary decision)
scored <-(select (scored, iBIPOC_pr:ClimateBL))
ScoredCasesIncluded <- nrow(scored)
ScoredCasesIncluded #this object is displayed below and I use input from  it for the inline text used in the write-up
PrScoredCellsMissing <-percent(mean(is.na(scored))) #percent missing across df
PrScoredRowsMissing <- percent(mean(complete.cases(scored))) #percent of rows with nonmissing data
PrScoredCellsMissing <-percent(mean(is.na(scored))) #percent missing across df
PrScoredRowsMissing <- percent(mean(complete.cases(scored))) #percent of rows with nonmissing data
PrScoredCellsMissing
PrScoredRowsMissing
#Using the package: mice
library(mice)
mice_ScaleLvl <- md.pattern(scored, plot = TRUE, rotate.names=TRUE)
item_scores_df <- read.csv ("BlStItmsScrs210320.csv", head = TRUE, sep = ",")
item_scores_df <- read.csv ("BlStItmsScrs210320.csv", head = TRUE, sep = ",")
View(item_scores_df)
library(psych)
library(formattable)
library(psych)
library(formattable)
Bel_alpha <- psych::alpha(item_scores_df[c("Belong_1", "Belong_2", "Belong_3")])
Bel_alpha
CClim_alpha <- psych::alpha(item_scores_df[c("rBlst_1", "Blst_2", "Blst_3", "Blst_4", "Blst_5", "Blst_6")])
CClim_alpha
Stigma_alpha <- psych::alpha(item_scores_df[c("Blst_3", "Blst_2", "Blst_5")])
Stigma_alpha
Resp_alpha <- psych::alpha(item_scores_df[c("rBlst_1", "Blst_4", "Blst_6")])
Resp_alpha
str(item_scores_df)
# the script may look a little complicated; I could have simply written
# describe(item_scores_df) #it would have given me descriptives for all the items in the df
# because I only wanted a few variables, I provided them in a concatenated: list [c("iBIPOC_pr", "cmBlack", "Belonging", "ClimateBL")]
# I also added "psych::" in front of the command to make sure that R is using the describe function from the psych package
# I popped the output into an object; objects are not required, but can be helpful to write as outfiles, to pipe elements of inline text, and to use with packages like apaTables
# When we use an object, we need to write it below so the results will display
descriptives <- (psych::describe(item_scores_df[c("iBIPOC_pr", "cmBlack", "Belonging", "ClimateBL")]))
descriptives
write.csv (descriptives, file="DataDx_descripts.csv") #this can be useful if you wish to manually format the data for an APA style table
#The shapiro-test is in base R; it's specification is simple:  shapiro.test(df$variable)
#I added the object (and had to list it below) so I can use the inline text function
SWt_i <- shapiro.test(item_scores_df$iBIPOC_pr)
SWt_cm <- shapiro.test(item_scores_df$cmBlack)
SWt_Bel <-shapiro.test(item_scores_df$Belonging)
SWt_Cl <-shapiro.test(item_scores_df$ClimateBL)
SWt_i
SWt_cm
SWt_Bel
SWt_Cl
iSW <- digits(SWt_i$statistic, 3)
iSWp <- digits(SWt_i$p.value, 4)
iSW
iSWp
cmSW <- digits(SWt_cm$statistic, 3)
cmSWp <- digits(SWt_cm$p.value, 4)
cmSW
cmSWp
belSW <- digits(SWt_Bel$statistic, 3)
belSWp <- digits(SWt_Bel$p.value, 4)
belSW
belSWp
clSW <- digits(SWt_Cl$statistic, 3)
clSWp <- digits(SWt_Cl$p.value, 4)
clSW
clSWp
psych::pairs.panels(item_scores_df[c("iBIPOC_pr", "cmBlack", "Belonging", "ClimateBL")], stars = TRUE, lm = TRUE)
item_scores_df$Mahal <- psych::outlier(item_scores_df[c("iBIPOC_pr", "cmBlack", "Belonging", "ClimateBL")])
psych::describe(item_scores_df$Mahal)
item_scores_df$MOutlier <- if_else(item_scores_df$Mahal > (median(item_scores_df$Mahal) + (3*sd(item_scores_df$Mahal))), TRUE, FALSE)
library(dplyr)
item_scores_df$MOutlier <- if_else(item_scores_df$Mahal > (median(item_scores_df$Mahal) + (3*sd(item_scores_df$Mahal))), TRUE, FALSE)
OutlierCount <- item_scores_df%>%
count(MOutlier)
OutlierCount
OutlierCount <- item_scores_df%>%
count(MOutlier)
OutlierCount
NumOutliers <- nrow(item_scores_df) - OutlierCount #calculating how many outliers
NumOutliers #this object is used for the inline text for the reesults
head(item_scores_df) #shows us the first 6 rows of the data so we can see the new variables (Mahal, MOutlier)
OutlierCount <- item_scores_df%>%
count(MOutlier)
OutlierCount
NumOutliers <- nrow(item_scores_df) - OutlierCount #calculating how many outliers
NumOutliers <- nrow(item_scores_df) - OutlierCount #calculating how many outliers
NumOutliers <- nrow(item_scores_df) - OutlierCount #calculating how many outliers
NumOutliers #this object is used for the inline text for the reesults
OutlierCount <- item_scores_df%>%
count(MOutlier)
OutlierCount
NumOutliers <- nrow(item_scores_df) - OutlierCount #calculating how many outliers
NumOutliers #this object is used for the inline text for the reesults
NumOutliers
head(item_scores_df) #shows us the first 6 rows of the data so we can see the new variables (Mahal, MOutlier)
Climate_fit <- lm(ClimateBL ~ Belonging + cmBlack + iBIPOC_pr, data = item_scores_df)
summary(Climate_fit)
library(apaTables)
apa.cor.table(item_scores_df[c("iBIPOC_pr", "cmBlack", "Belonging", "ClimateBL")], table.number = 1, show.sig.stars = TRUE, filename = "Table1_M_SDs_r_DataDx")
library(apaTables)
apaTables::apa.reg.table(Climate_fit, table.number = 2, filename = "Climate_table.doc")
citr:::insert_citation()
